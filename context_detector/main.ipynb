{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code: \n",
    "https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch torchvision torchaudio\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\context_detector\\env\\lib\\site-packages\\torch\\cuda\\memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\Desktop\\context_detector\\env\\lib\\site-packages\\torch\\cuda\\memory.py:356: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# Clear CUDA cache function\n",
    "def clear_cuda_cache():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.reset_max_memory_cached()\n",
    "    gc.collect()\n",
    "\n",
    "clear_cuda_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\context_detector\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Check torch and CUDA versions\n",
    "print(torch.__version__)  # Should display the version of PyTorch with CUDA support\n",
    "print(torch.version.cuda)  # Should display the CUDA version\n",
    "print(torch.backends.cudnn.version())  # Should display the cuDNN version\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "\n",
    "\n",
    "# Set global variables and tokenizer parameters\n",
    "SUBSAMPLE = False\n",
    "SEED = 42\n",
    "LR = 1e-5\n",
    "PLOT_EDA = False\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "\n",
    "tokenizer_params = {\n",
    "    'add_special_tokens': True,     # adds [CLS] and [SEP] tags\n",
    "    'return_attention_mask': True,  # useful for distinguishing between actual data and padding\n",
    "    'pad_to_max_length': True,      # to ensure all sequences have the same length\n",
    "    'truncation': True,\n",
    "    'max_length': 128,  #256             # set the maximum length for sequences\n",
    "    'return_tensors': 'pt'          # use 'pt' when using PyTorch, 'tf' for TensorFlow\n",
    "}\n",
    "\n",
    "# Load data \n",
    "print(\"Loading raw data...\")\n",
    "data = pd.read_csv('consumer_complaints.csv')\n",
    "data = data[['product', 'consumer_complaint_narrative']]\n",
    "\n",
    "### PREPROCESSING\n",
    "# Drop rows with all columns missing and underrepresented categories\n",
    "data = data.dropna()\n",
    "categories_to_drop = ['Consumer Loan', \n",
    "                    'Bank account or service',\n",
    "                    'Student loan', \n",
    "                    'Prepaid card',\n",
    "                    'Payday loan', \n",
    "                    'Money transfers', \n",
    "                    'Other financial service']\n",
    "data = data[~data['product'].isin(categories_to_drop)]\n",
    "\n",
    "# Sub-sample to speed up the training process \n",
    "if SUBSAMPLE: \n",
    "    data = data.sample(frac=0.25, random_state=SEED)\n",
    "\n",
    "if PLOT_EDA: \n",
    "    # EDA plots\n",
    "    # 1. Create a histogram with the word count for the column 'consumer_complaint_narrative'\n",
    "    data['narrative_word_count'] = data['consumer_complaint_narrative'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(data['narrative_word_count'], bins=30, edgecolor='k', alpha=0.7)\n",
    "    plt.title('Histogram of Word Count in Consumer Complaint Narratives')\n",
    "    plt.xlabel('Word Count')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Create a barplot counting each unique value in the column 'issue'\n",
    "    issue_counts = data['product'].value_counts()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    issue_counts.plot(kind='bar', color='skyblue', edgecolor='k', alpha=0.7)\n",
    "    plt.title('Barplot of Issues in Consumer Complaints')\n",
    "    plt.xlabel('Product')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Encoding labels\n",
    "labels_ = data['product'].unique()\n",
    "label_dict = {}\n",
    "for idx, labels_ in enumerate(labels_):\n",
    "    label_dict[labels_] = idx\n",
    "\n",
    "# Encode product labels\n",
    "data['label'] = data['product'].replace(label_dict)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data.index.values,\n",
    "    data['label'].values,\n",
    "    test_size = 0.2,\n",
    "    random_state=SEED,\n",
    "    stratify = data['label'])\n",
    "\n",
    "# Define data type in the original dataset\n",
    "data['data_type'] = ['not_set'] * data.shape[0]\n",
    "data.loc[X_train, 'data_type'] = 'train'\n",
    "data.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "print('Loading tokenizer')\n",
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('bert-base-uncased',   # model name\n",
    "                                          do_lower_case=True)    # convert to lowercase\n",
    "\n",
    "print('format')\n",
    "print(data[data.data_type=='train']['consumer_complaint_narrative'].values)\n",
    "\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='train']['consumer_complaint_narrative'].values,\n",
    "    **tokenizer_params\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='val']['consumer_complaint_narrative'].values,\n",
    "    **tokenizer_params\n",
    ")\n",
    "\n",
    "print('Extracting tokens...')\n",
    "# Extract token input IDs and attention masks\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "\n",
    "# Convert labels into tensors\n",
    "labels_train = torch.tensor(data[data.data_type=='train']['label'].values)\n",
    "\n",
    "# Repeat process for validation data\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(data[data.data_type=='val']['label'].values)\n",
    "\n",
    "# Create tensor \n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "print(\"Load model...\")\n",
    "# lOAD PRE-TRAINED MODEL \n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler=RandomSampler(dataset_train),\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val,\n",
    "                                   sampler=SequentialSampler(dataset_val),\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "# AdamW for Adam optimization with Weight decay\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=LR,   \n",
    "                  eps=1e-8)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=100,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define accuracy functions\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "\n",
    "def accuracy_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return accuracy_score(labels_flat, preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.12497114647304253\n",
      "Class: Debt collection\n",
      "Accuracy: 0/889\n",
      "\n",
      "Class: Mortgage\n",
      "Accuracy: 735/736\n",
      "\n",
      "Class: Credit card\n",
      "Accuracy: 3/402\n",
      "\n",
      "Class: Credit reporting\n",
      "Accuracy: 2/620\n",
      "\n",
      "Initial Accuracy (Before Fine-tuning): 0.2795617680392898\n"
     ]
    }
   ],
   "source": [
    "### CREATE BENCHMARK USING A ZERO-SHOT MODEL \n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    preds, true_vals = [], []\n",
    "    for batch in dataloader:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        preds.append(outputs.logits.detach().cpu().numpy())\n",
    "        true_vals.append(inputs['labels'].detach().cpu().numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "    return preds, true_vals\n",
    "\n",
    "# Load the model and data on the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Initial evaluation on validation set\n",
    "initial_preds, initial_true_vals = evaluate(model, dataloader_validation)\n",
    "initial_f1_score = f1_score_func(initial_preds, initial_true_vals)\n",
    "print(f'F1 Score: {initial_f1_score}')\n",
    "accuracy_per_class(initial_preds, initial_true_vals)\n",
    "\n",
    "\n",
    "initial_preds, initial_true_vals = evaluate(model, dataloader_validation)\n",
    "initial_accuracy = accuracy_func(initial_preds, initial_true_vals)\n",
    "print(f'Initial Accuracy (Before Fine-tuning): {initial_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [03:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.5199072419105554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [03:14<12:59, 194.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.39405947710334693\n",
      "F1 Score (Weighted): 0.8864404857768816\n",
      "Accuracy: 0.8866641480921799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [06:17<12:59, 194.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.2818589627398028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [06:29<09:44, 194.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.4005648374329058\n",
      "F1 Score (Weighted): 0.8963153687242554\n",
      "Accuracy: 0.8968643747638836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [09:32<09:44, 194.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.19576745001534115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [09:44<06:29, 194.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.42825636858349\n",
      "F1 Score (Weighted): 0.8974206772945613\n",
      "Accuracy: 0.8976199471099358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [12:49<06:29, 194.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.1246876636758795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [13:00<03:15, 195.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5305367338409612\n",
      "F1 Score (Weighted): 0.8978599563894261\n",
      "Accuracy: 0.8979977332829618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [15:59<03:15, 195.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.08573310245239599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [16:11<00:00, 194.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5378467668552953\n",
      "F1 Score (Weighted): 0.8963541599122408\n",
      "Accuracy: 0.8964865885908576\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "def accuracy_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return accuracy_score(labels_flat, preds_flat)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "# Initialize lists to store losses for plotting\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Ensure the directory for saving models exists\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, ncols=100)\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "    # Save the model at each epoch \n",
    "    torch.save(model.state_dict(), f'models/finetuned_BERT_epoch_{epoch}.model')\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    training_losses.append(loss_train_avg)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    val_accuracy = accuracy_func(predictions, true_vals)\n",
    "    validation_losses.append(val_loss)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    tqdm.write(f'Accuracy: {val_accuracy}')\n",
    "\n",
    "# Plotting the training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs + 1), training_losses, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best model to compare how it classifies between classes compared to the original benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from epoch 2...\n",
      "F1 Score: 0.8963153687242554\n",
      "Accuracy: 0.8968643747638836\n",
      "Class: Debt collection\n",
      "Accuracy: 806/889\n",
      "\n",
      "Class: Mortgage\n",
      "Accuracy: 710/736\n",
      "\n",
      "Class: Credit card\n",
      "Accuracy: 349/402\n",
      "\n",
      "Class: Credit reporting\n",
      "Accuracy: 509/620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    preds, true_vals = [], []\n",
    "    for batch in dataloader:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        preds.append(outputs[1].detach().cpu().numpy())  # logits are at index 1\n",
    "        true_vals.append(inputs['labels'].detach().cpu().numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "    return preds, true_vals\n",
    "\n",
    "# Function to print class-wise accuracy\n",
    "# def accuracy_per_class(preds, labels, label_dict):\n",
    "#     preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "#     labels_flat = labels.flatten()\n",
    "#     label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "#     for label in np.unique(labels_flat):\n",
    "#         y_preds = preds_flat[labels_flat == label]\n",
    "#         y_true = labels_flat[labels_flat == label]\n",
    "#         accuracy = len(y_preds[y_preds == label]) / len(y_true)\n",
    "#         print(f'Class: {label_dict_inverse[label]}')\n",
    "#         print(f'Accuracy: {len(y_preds[y_preds == label])}/{len(y_true)}\\n')\n",
    "\n",
    "# Load and evaluate the model from epoch 2\n",
    "print(\"Loading model from epoch 2...\")\n",
    "model.load_state_dict(torch.load('models/finetuned_BERT_epoch_2.model'))\n",
    "model.to(device)\n",
    "preds_epoch_3, true_vals_epoch_3 = evaluate(model, dataloader_validation)\n",
    "f1_score_epoch_3 = f1_score_func(preds_epoch_3, true_vals_epoch_3)\n",
    "accuracy_epoch_3 = accuracy_func(preds_epoch_3, true_vals_epoch_3)\n",
    "\n",
    "# Print F1 score and overall accuracy\n",
    "print(f'F1 Score: {f1_score_epoch_3}')\n",
    "print(f'Accuracy: {accuracy_epoch_3}')\n",
    "\n",
    "# Print class-wise accuracy\n",
    "accuracy_per_class(preds_epoch_3, true_vals_epoch_3, label_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.weight', 'bert.pooler.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.pooler.dense.bias', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.10.intermediate.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'cls.predictions.decoder.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'cls.predictions.bias', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.4.attention.self.key.bias', 'cls.seq_relationship.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.value.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['transformer.layer.0.attention.v_lin.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.6.attention.k_lin.bias', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.7.ffn.lin2.bias', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.7.output_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.10.attention.k_lin.weight', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.10.sa_layer_norm.weight', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.7.attention.v_lin.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.9.ffn.lin2.bias', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.8.attention.k_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.8.attention.out_lin.weight', 'transformer.layer.9.ffn.lin1.weight', 'transformer.layer.2.attention.out_lin.weight', 'pre_classifier.bias', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.7.attention.v_lin.weight', 'transformer.layer.6.ffn.lin1.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.10.attention.v_lin.weight', 'transformer.layer.8.attention.out_lin.bias', 'transformer.layer.11.attention.q_lin.weight', 'transformer.layer.7.attention.out_lin.bias', 'transformer.layer.7.ffn.lin1.weight', 'transformer.layer.11.attention.out_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.11.ffn.lin1.weight', 'transformer.layer.11.output_layer_norm.weight', 'transformer.layer.10.output_layer_norm.bias', 'transformer.layer.11.ffn.lin2.bias', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.8.output_layer_norm.weight', 'transformer.layer.6.sa_layer_norm.weight', 'embeddings.word_embeddings.weight', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.6.output_layer_norm.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.11.output_layer_norm.bias', 'transformer.layer.9.output_layer_norm.weight', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.6.attention.q_lin.bias', 'transformer.layer.10.attention.q_lin.bias', 'transformer.layer.11.attention.v_lin.weight', 'transformer.layer.6.output_layer_norm.weight', 'transformer.layer.11.ffn.lin2.weight', 'transformer.layer.8.ffn.lin1.weight', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.6.attention.k_lin.weight', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.8.attention.q_lin.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.8.attention.q_lin.bias', 'transformer.layer.7.attention.q_lin.weight', 'transformer.layer.9.ffn.lin1.bias', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.6.ffn.lin2.bias', 'transformer.layer.8.attention.v_lin.weight', 'transformer.layer.11.sa_layer_norm.weight', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.10.attention.k_lin.bias', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.7.ffn.lin1.bias', 'transformer.layer.8.output_layer_norm.bias', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.6.attention.out_lin.bias', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.2.ffn.lin2.weight', 'classifier.weight', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.11.attention.q_lin.bias', 'transformer.layer.9.sa_layer_norm.weight', 'transformer.layer.7.attention.q_lin.bias', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.7.output_layer_norm.bias', 'transformer.layer.10.ffn.lin2.weight', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.9.attention.out_lin.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.6.sa_layer_norm.bias', 'transformer.layer.7.attention.k_lin.weight', 'transformer.layer.9.attention.q_lin.bias', 'embeddings.position_embeddings.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.8.ffn.lin2.weight', 'pre_classifier.weight', 'transformer.layer.9.ffn.lin2.weight', 'transformer.layer.10.ffn.lin1.weight', 'transformer.layer.6.attention.out_lin.weight', 'classifier.bias', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.6.ffn.lin1.weight', 'transformer.layer.3.attention.q_lin.bias', 'embeddings.LayerNorm.weight', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.6.attention.v_lin.weight', 'transformer.layer.7.sa_layer_norm.weight', 'transformer.layer.8.attention.v_lin.bias', 'transformer.layer.8.sa_layer_norm.weight', 'transformer.layer.11.attention.k_lin.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.7.ffn.lin2.weight', 'transformer.layer.8.ffn.lin1.bias', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.6.ffn.lin2.weight', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.10.attention.q_lin.weight', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.6.attention.q_lin.weight', 'transformer.layer.11.attention.out_lin.bias', 'embeddings.LayerNorm.bias', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.9.attention.k_lin.bias', 'transformer.layer.10.ffn.lin1.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.8.ffn.lin2.bias', 'transformer.layer.7.attention.k_lin.bias', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.9.attention.v_lin.weight', 'transformer.layer.10.sa_layer_norm.bias', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.10.attention.v_lin.bias', 'transformer.layer.7.sa_layer_norm.bias', 'transformer.layer.9.output_layer_norm.bias', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.9.attention.out_lin.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.7.attention.out_lin.weight', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.10.ffn.lin2.bias', 'transformer.layer.9.attention.k_lin.weight', 'transformer.layer.10.attention.out_lin.weight', 'transformer.layer.9.attention.q_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.8.sa_layer_norm.bias', 'transformer.layer.9.sa_layer_norm.bias', 'transformer.layer.11.sa_layer_norm.bias', 'transformer.layer.10.output_layer_norm.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.10.attention.out_lin.bias', 'transformer.layer.6.attention.v_lin.bias', 'transformer.layer.9.attention.v_lin.bias', 'transformer.layer.11.ffn.lin1.bias', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.11.attention.k_lin.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.11.attention.v_lin.bias', 'transformer.layer.8.attention.k_lin.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.0.ffn.lin1.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DistilBertForSequenceClassification:\n\tMissing key(s) in state_dict: \"distilbert.transformer.layer.6.attention.q_lin.weight\", \"distilbert.transformer.layer.6.attention.q_lin.bias\", \"distilbert.transformer.layer.6.attention.k_lin.weight\", \"distilbert.transformer.layer.6.attention.k_lin.bias\", \"distilbert.transformer.layer.6.attention.v_lin.weight\", \"distilbert.transformer.layer.6.attention.v_lin.bias\", \"distilbert.transformer.layer.6.attention.out_lin.weight\", \"distilbert.transformer.layer.6.attention.out_lin.bias\", \"distilbert.transformer.layer.6.sa_layer_norm.weight\", \"distilbert.transformer.layer.6.sa_layer_norm.bias\", \"distilbert.transformer.layer.6.ffn.lin1.weight\", \"distilbert.transformer.layer.6.ffn.lin1.bias\", \"distilbert.transformer.layer.6.ffn.lin2.weight\", \"distilbert.transformer.layer.6.ffn.lin2.bias\", \"distilbert.transformer.layer.6.output_layer_norm.weight\", \"distilbert.transformer.layer.6.output_layer_norm.bias\", \"distilbert.transformer.layer.7.attention.q_lin.weight\", \"distilbert.transformer.layer.7.attention.q_lin.bias\", \"distilbert.transformer.layer.7.attention.k_lin.weight\", \"distilbert.transformer.layer.7.attention.k_lin.bias\", \"distilbert.transformer.layer.7.attention.v_lin.weight\", \"distilbert.transformer.layer.7.attention.v_lin.bias\", \"distilbert.transformer.layer.7.attention.out_lin.weight\", \"distilbert.transformer.layer.7.attention.out_lin.bias\", \"distilbert.transformer.layer.7.sa_layer_norm.weight\", \"distilbert.transformer.layer.7.sa_layer_norm.bias\", \"distilbert.transformer.layer.7.ffn.lin1.weight\", \"distilbert.transformer.layer.7.ffn.lin1.bias\", \"distilbert.transformer.layer.7.ffn.lin2.weight\", \"distilbert.transformer.layer.7.ffn.lin2.bias\", \"distilbert.transformer.layer.7.output_layer_norm.weight\", \"distilbert.transformer.layer.7.output_layer_norm.bias\", \"distilbert.transformer.layer.8.attention.q_lin.weight\", \"distilbert.transformer.layer.8.attention.q_lin.bias\", \"distilbert.transformer.layer.8.attention.k_lin.weight\", \"distilbert.transformer.layer.8.attention.k_lin.bias\", \"distilbert.transformer.layer.8.attention.v_lin.weight\", \"distilbert.transformer.layer.8.attention.v_lin.bias\", \"distilbert.transformer.layer.8.attention.out_lin.weight\", \"distilbert.transformer.layer.8.attention.out_lin.bias\", \"distilbert.transformer.layer.8.sa_layer_norm.weight\", \"distilbert.transformer.layer.8.sa_layer_norm.bias\", \"distilbert.transformer.layer.8.ffn.lin1.weight\", \"distilbert.transformer.layer.8.ffn.lin1.bias\", \"distilbert.transformer.layer.8.ffn.lin2.weight\", \"distilbert.transformer.layer.8.ffn.lin2.bias\", \"distilbert.transformer.layer.8.output_layer_norm.weight\", \"distilbert.transformer.layer.8.output_layer_norm.bias\", \"distilbert.transformer.layer.9.attention.q_lin.weight\", \"distilbert.transformer.layer.9.attention.q_lin.bias\", \"distilbert.transformer.layer.9.attention.k_lin.weight\", \"distilbert.transformer.layer.9.attention.k_lin.bias\", \"distilbert.transformer.layer.9.attention.v_lin.weight\", \"distilbert.transformer.layer.9.attention.v_lin.bias\", \"distilbert.transformer.layer.9.attention.out_lin.weight\", \"distilbert.transformer.layer.9.attention.out_lin.bias\", \"distilbert.transformer.layer.9.sa_layer_norm.weight\", \"distilbert.transformer.layer.9.sa_layer_norm.bias\", \"distilbert.transformer.layer.9.ffn.lin1.weight\", \"distilbert.transformer.layer.9.ffn.lin1.bias\", \"distilbert.transformer.layer.9.ffn.lin2.weight\", \"distilbert.transformer.layer.9.ffn.lin2.bias\", \"distilbert.transformer.layer.9.output_layer_norm.weight\", \"distilbert.transformer.layer.9.output_layer_norm.bias\", \"distilbert.transformer.layer.10.attention.q_lin.weight\", \"distilbert.transformer.layer.10.attention.q_lin.bias\", \"distilbert.transformer.layer.10.attention.k_lin.weight\", \"distilbert.transformer.layer.10.attention.k_lin.bias\", \"distilbert.transformer.layer.10.attention.v_lin.weight\", \"distilbert.transformer.layer.10.attention.v_lin.bias\", \"distilbert.transformer.layer.10.attention.out_lin.weight\", \"distilbert.transformer.layer.10.attention.out_lin.bias\", \"distilbert.transformer.layer.10.sa_layer_norm.weight\", \"distilbert.transformer.layer.10.sa_layer_norm.bias\", \"distilbert.transformer.layer.10.ffn.lin1.weight\", \"distilbert.transformer.layer.10.ffn.lin1.bias\", \"distilbert.transformer.layer.10.ffn.lin2.weight\", \"distilbert.transformer.layer.10.ffn.lin2.bias\", \"distilbert.transformer.layer.10.output_layer_norm.weight\", \"distilbert.transformer.layer.10.output_layer_norm.bias\", \"distilbert.transformer.layer.11.attention.q_lin.weight\", \"distilbert.transformer.layer.11.attention.q_lin.bias\", \"distilbert.transformer.layer.11.attention.k_lin.weight\", \"distilbert.transformer.layer.11.attention.k_lin.bias\", \"distilbert.transformer.layer.11.attention.v_lin.weight\", \"distilbert.transformer.layer.11.attention.v_lin.bias\", \"distilbert.transformer.layer.11.attention.out_lin.weight\", \"distilbert.transformer.layer.11.attention.out_lin.bias\", \"distilbert.transformer.layer.11.sa_layer_norm.weight\", \"distilbert.transformer.layer.11.sa_layer_norm.bias\", \"distilbert.transformer.layer.11.ffn.lin1.weight\", \"distilbert.transformer.layer.11.ffn.lin1.bias\", \"distilbert.transformer.layer.11.ffn.lin2.weight\", \"distilbert.transformer.layer.11.ffn.lin2.bias\", \"distilbert.transformer.layer.11.output_layer_norm.weight\", \"distilbert.transformer.layer.11.output_layer_norm.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load best model and make prediction\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/finetuned_BERT_epoch_2.model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m _, predictions, true_vals \u001b[38;5;241m=\u001b[39m evaluate(dataloader_validation)\n\u001b[0;32m     10\u001b[0m accuracy_per_class(predictions, true_vals)\n",
      "File \u001b[1;32mc:\\Users\\hp\\Desktop\\context_detector\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DistilBertForSequenceClassification:\n\tMissing key(s) in state_dict: \"distilbert.transformer.layer.6.attention.q_lin.weight\", \"distilbert.transformer.layer.6.attention.q_lin.bias\", \"distilbert.transformer.layer.6.attention.k_lin.weight\", \"distilbert.transformer.layer.6.attention.k_lin.bias\", \"distilbert.transformer.layer.6.attention.v_lin.weight\", \"distilbert.transformer.layer.6.attention.v_lin.bias\", \"distilbert.transformer.layer.6.attention.out_lin.weight\", \"distilbert.transformer.layer.6.attention.out_lin.bias\", \"distilbert.transformer.layer.6.sa_layer_norm.weight\", \"distilbert.transformer.layer.6.sa_layer_norm.bias\", \"distilbert.transformer.layer.6.ffn.lin1.weight\", \"distilbert.transformer.layer.6.ffn.lin1.bias\", \"distilbert.transformer.layer.6.ffn.lin2.weight\", \"distilbert.transformer.layer.6.ffn.lin2.bias\", \"distilbert.transformer.layer.6.output_layer_norm.weight\", \"distilbert.transformer.layer.6.output_layer_norm.bias\", \"distilbert.transformer.layer.7.attention.q_lin.weight\", \"distilbert.transformer.layer.7.attention.q_lin.bias\", \"distilbert.transformer.layer.7.attention.k_lin.weight\", \"distilbert.transformer.layer.7.attention.k_lin.bias\", \"distilbert.transformer.layer.7.attention.v_lin.weight\", \"distilbert.transformer.layer.7.attention.v_lin.bias\", \"distilbert.transformer.layer.7.attention.out_lin.weight\", \"distilbert.transformer.layer.7.attention.out_lin.bias\", \"distilbert.transformer.layer.7.sa_layer_norm.weight\", \"distilbert.transformer.layer.7.sa_layer_norm.bias\", \"distilbert.transformer.layer.7.ffn.lin1.weight\", \"distilbert.transformer.layer.7.ffn.lin1.bias\", \"distilbert.transformer.layer.7.ffn.lin2.weight\", \"distilbert.transformer.layer.7.ffn.lin2.bias\", \"distilbert.transformer.layer.7.output_layer_norm.weight\", \"distilbert.transformer.layer.7.output_layer_norm.bias\", \"distilbert.transformer.layer.8.attention.q_lin.weight\", \"distilbert.transformer.layer.8.attention.q_lin.bias\", \"distilbert.transformer.layer.8.attention.k_lin.weight\", \"distilbert.transformer.layer.8.attention.k_lin.bias\", \"distilbert.transformer.layer.8.attention.v_lin.weight\", \"distilbert.transformer.layer.8.attention.v_lin.bias\", \"distilbert.transformer.layer.8.attention.out_lin.weight\", \"distilbert.transformer.layer.8.attention.out_lin.bias\", \"distilbert.transformer.layer.8.sa_layer_norm.weight\", \"distilbert.transformer.layer.8.sa_layer_norm.bias\", \"distilbert.transformer.layer.8.ffn.lin1.weight\", \"distilbert.transformer.layer.8.ffn.lin1.bias\", \"distilbert.transformer.layer.8.ffn.lin2.weight\", \"distilbert.transformer.layer.8.ffn.lin2.bias\", \"distilbert.transformer.layer.8.output_layer_norm.weight\", \"distilbert.transformer.layer.8.output_layer_norm.bias\", \"distilbert.transformer.layer.9.attention.q_lin.weight\", \"distilbert.transformer.layer.9.attention.q_lin.bias\", \"distilbert.transformer.layer.9.attention.k_lin.weight\", \"distilbert.transformer.layer.9.attention.k_lin.bias\", \"distilbert.transformer.layer.9.attention.v_lin.weight\", \"distilbert.transformer.layer.9.attention.v_lin.bias\", \"distilbert.transformer.layer.9.attention.out_lin.weight\", \"distilbert.transformer.layer.9.attention.out_lin.bias\", \"distilbert.transformer.layer.9.sa_layer_norm.weight\", \"distilbert.transformer.layer.9.sa_layer_norm.bias\", \"distilbert.transformer.layer.9.ffn.lin1.weight\", \"distilbert.transformer.layer.9.ffn.lin1.bias\", \"distilbert.transformer.layer.9.ffn.lin2.weight\", \"distilbert.transformer.layer.9.ffn.lin2.bias\", \"distilbert.transformer.layer.9.output_layer_norm.weight\", \"distilbert.transformer.layer.9.output_layer_norm.bias\", \"distilbert.transformer.layer.10.attention.q_lin.weight\", \"distilbert.transformer.layer.10.attention.q_lin.bias\", \"distilbert.transformer.layer.10.attention.k_lin.weight\", \"distilbert.transformer.layer.10.attention.k_lin.bias\", \"distilbert.transformer.layer.10.attention.v_lin.weight\", \"distilbert.transformer.layer.10.attention.v_lin.bias\", \"distilbert.transformer.layer.10.attention.out_lin.weight\", \"distilbert.transformer.layer.10.attention.out_lin.bias\", \"distilbert.transformer.layer.10.sa_layer_norm.weight\", \"distilbert.transformer.layer.10.sa_layer_norm.bias\", \"distilbert.transformer.layer.10.ffn.lin1.weight\", \"distilbert.transformer.layer.10.ffn.lin1.bias\", \"distilbert.transformer.layer.10.ffn.lin2.weight\", \"distilbert.transformer.layer.10.ffn.lin2.bias\", \"distilbert.transformer.layer.10.output_layer_norm.weight\", \"distilbert.transformer.layer.10.output_layer_norm.bias\", \"distilbert.transformer.layer.11.attention.q_lin.weight\", \"distilbert.transformer.layer.11.attention.q_lin.bias\", \"distilbert.transformer.layer.11.attention.k_lin.weight\", \"distilbert.transformer.layer.11.attention.k_lin.bias\", \"distilbert.transformer.layer.11.attention.v_lin.weight\", \"distilbert.transformer.layer.11.attention.v_lin.bias\", \"distilbert.transformer.layer.11.attention.out_lin.weight\", \"distilbert.transformer.layer.11.attention.out_lin.bias\", \"distilbert.transformer.layer.11.sa_layer_norm.weight\", \"distilbert.transformer.layer.11.sa_layer_norm.bias\", \"distilbert.transformer.layer.11.ffn.lin1.weight\", \"distilbert.transformer.layer.11.ffn.lin1.bias\", \"distilbert.transformer.layer.11.ffn.lin2.weight\", \"distilbert.transformer.layer.11.ffn.lin2.bias\", \"distilbert.transformer.layer.11.output_layer_norm.weight\", \"distilbert.transformer.layer.11.output_layer_norm.bias\". "
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Load best model and make prediction\n",
    "model.load_state_dict(torch.load('models/finetuned_BERT_epoch_2.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model using one sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tunning with data augmentation \n",
    "\n",
    "Data augmentation techniques: \n",
    "1. Synonym replacement \n",
    "2. Random insertion \n",
    "3. Random swap \n",
    "4. Random deletion \n",
    "5. Back translation \n",
    "6. Noise injection \n",
    "\n",
    "\n",
    "Use data augmentation during model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nlpaug\n",
    "# !pip install nltk\n",
    "# !python -m nltk.downloader all\n",
    "# !pip install wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# import nlpaug.augmenter.word as naw\n",
    "# import nltk\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# aug_syn = naw.SynonymAug(aug_src='wordnet')\n",
    "# # aug_insert = naw.RandomWordAug(action=\"insert\")\n",
    "# aug_swap = naw.RandomWordAug(action=\"swap\")\n",
    "# aug_delete = naw.RandomWordAug(action=\"delete\")\n",
    "# augmenters = [aug_syn, aug_swap, aug_delete]\n",
    "\n",
    "# # Apply data augmentation to data \n",
    "# def augment_text(text, augmenters, num_augmentations=1):\n",
    "#     augmented_texts = [text]\n",
    "#     for _ in range(num_augmentations):\n",
    "#         augmenter = random.choice(augmenters)\n",
    "#         augmented_text = augmenter.augment(text)\n",
    "#         augmented_texts.append(augmented_text)\n",
    "#     return augmented_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\context_detector\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# augmented_data = []\n",
    "# for index, row in data.iterrows():\n",
    "#     text = row['consumer_complaint_narrative']\n",
    "#     augmented_texts = augment_text(text, augmenters, num_augmentations=2)\n",
    "#     for augmented_text in augmented_texts:\n",
    "#         augmented_data.append((augmented_text, row['label']))\n",
    "\n",
    "# # Create new dataframe with augmented data and combine it with original dataset\n",
    "# augmented_df = pd.DataFrame(augmented_data, columns=['consumer_complaint_narrative', 'label'])\n",
    "# data = pd.concat([data, augmented_df], ignore_index=True)\n",
    "\n",
    "# # Continue with tokenization and creating DataLoader as before\n",
    "# encoded_data_train = tokenizer.batch_encode_plus(\n",
    "#     data[data.data_type=='train']['consumer_complaint_narrative'].values,\n",
    "#     **tokenizer_params\n",
    "# )\n",
    "\n",
    "# encoded_data_val = tokenizer.batch_encode_plus(\n",
    "#     data[data.data_type=='val']['consumer_complaint_narrative'].values,\n",
    "#     **tokenizer_params\n",
    "# )\n",
    "\n",
    "# input_ids_train = encoded_data_train['input_ids']\n",
    "# attention_masks_train = encoded_data_train['attention_mask']\n",
    "# labels_train = torch.tensor(data[data.data_type=='train']['label'].values)\n",
    "\n",
    "# input_ids_val = encoded_data_val['input_ids']\n",
    "# attention_masks_val = encoded_data_val['attention_mask']\n",
    "# labels_val = torch.tensor(data[data.data_type=='val']['label'].values)\n",
    "\n",
    "# dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "# dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "# dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "# dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [04:45<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.15893469988218947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [05:07<20:31, 307.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5018551978493496\n",
      "F1 Score (Weighted): 0.8845496386829244\n",
      "Accuracy: 0.8843974310540235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [09:53<20:31, 307.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.1529485837413953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [10:15<15:23, 307.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5018551978493496\n",
      "F1 Score (Weighted): 0.8845496386829244\n",
      "Accuracy: 0.8843974310540235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [14:59<15:23, 307.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.154154187168379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [15:21<10:13, 306.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5018551978493496\n",
      "F1 Score (Weighted): 0.8845496386829244\n",
      "Accuracy: 0.8843974310540235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [20:03<10:13, 306.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.15416813386794148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [20:26<05:06, 306.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5018551978493496\n",
      "F1 Score (Weighted): 0.8845496386829244\n",
      "Accuracy: 0.8843974310540235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [25:13<05:06, 306.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.15728549454475527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [25:35<00:00, 307.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5018551978493496\n",
      "F1 Score (Weighted): 0.8845496386829244\n",
      "Accuracy: 0.8843974310540235\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Run model on augmented data \n",
    "# # Check for GPU\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# print(\"Starting model training...\")\n",
    "# # Move model to device\n",
    "# model.to(device)\n",
    "\n",
    "# # Evaluation function\n",
    "# def evaluate(dataloader_val):\n",
    "#     model.eval()\n",
    "#     loss_val_total = 0\n",
    "#     predictions, true_vals = [], []\n",
    "\n",
    "#     for batch in dataloader_val:\n",
    "#         batch = tuple(b.to(device) for b in batch)\n",
    "#         inputs = {\n",
    "#             'input_ids': batch[0],\n",
    "#             'attention_mask': batch[1],\n",
    "#             'labels': batch[2],\n",
    "#         }\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "#         loss = outputs[0]\n",
    "#         logits = outputs[1]\n",
    "#         loss_val_total += loss.item()\n",
    "#         logits = logits.detach().cpu().numpy()\n",
    "#         label_ids = inputs['labels'].cpu().numpy()\n",
    "#         predictions.append(logits)\n",
    "#         true_vals.append(label_ids)\n",
    "\n",
    "#     loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "#     predictions = np.concatenate(predictions, axis=0)\n",
    "#     true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "#     return loss_val_avg, predictions, true_vals\n",
    "\n",
    "# # Initialize lists to store losses for plotting\n",
    "# training_losses = []\n",
    "# validation_losses = []\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in tqdm(range(1, epochs + 1)):\n",
    "#     model.train()\n",
    "#     loss_train_total = 0\n",
    "#     progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, ncols=100)\n",
    "#     for batch in progress_bar:\n",
    "#         model.zero_grad()\n",
    "#         batch = tuple(b.to(device) for b in batch)\n",
    "#         inputs = {\n",
    "#             'input_ids': batch[0],\n",
    "#             'attention_mask': batch[1],\n",
    "#             'labels': batch[2],\n",
    "#         }\n",
    "#         outputs = model(**inputs)\n",
    "#         loss = outputs[0]\n",
    "#         loss_train_total += loss.item()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "#         progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "#     # Save the model at each epoch \n",
    "#     torch.save(model.state_dict(), f'models/finetuned_BERT_epoch_aug_{epoch}.model')\n",
    "\n",
    "#     tqdm.write(f'\\nEpoch {epoch}')\n",
    "#     loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "#     training_losses.append(loss_train_avg)\n",
    "#     tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "#     val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "#     val_f1 = f1_score_func(predictions, true_vals)\n",
    "#     val_accuracy = accuracy_func(predictions, true_vals)\n",
    "#     validation_losses.append(val_loss)\n",
    "#     tqdm.write(f'Validation loss: {val_loss}')\n",
    "#     tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "#     tqdm.write(f'Accuracy: {val_accuracy}')\n",
    "\n",
    "# # Plotting the training and validation losses\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, epochs + 1), training_losses, label='Training Loss')\n",
    "# plt.plot(range(1, epochs + 1), validation_losses, label='Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss Over Time')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom model\n",
    "Resolve unbalancement using data augmentation on undersampled categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the code above including: \n",
    "- data augmentation for minority categories\n",
    "- regularization to stabilize validation loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_21024\\1198939761.py:38: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('consumer_complaints.csv')\n",
      "c:\\Users\\hp\\Desktop\\context_detector\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [08:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.498710506214413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [08:40<1:18:02, 520.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3961485666622009\n",
      "F1 Score (Weighted): 0.879030594415266\n",
      "Accuracy: 0.8782401091405184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [17:02<1:18:02, 520.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.22101690399227503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [17:28<1:09:57, 524.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.4863618822426212\n",
      "F1 Score (Weighted): 0.8883099792207994\n",
      "Accuracy: 0.888130968622101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [25:48<1:09:57, 524.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.1133847022731981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [26:13<1:01:16, 525.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6229034648049975\n",
      "F1 Score (Weighted): 0.8799340444334302\n",
      "Accuracy: 0.8799454297407913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# import nlpaug.augmenter.word as naw\n",
    "# from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from sklearn.metrics import f1_score, accuracy_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import torch\n",
    "\n",
    "# # Check torch and CUDA versions\n",
    "# print(torch.__version__)  # Should display the version of PyTorch with CUDA support\n",
    "# print(torch.version.cuda)  # Should display the CUDA version\n",
    "# print(torch.backends.cudnn.version())  # Should display the cuDNN version\n",
    "# print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "\n",
    "\n",
    "\n",
    "# Set global variables and tokenizer parameters\n",
    "SUBSAMPLE = False\n",
    "DROPOUT_RATE = 0.5\n",
    "WEIGHT_DECAY = 0.02\n",
    "SEED = 42\n",
    "LR = 2e-5\n",
    "batch_size = 12\n",
    "epochs = 3\n",
    "\n",
    "tokenizer_params = {\n",
    "    'add_special_tokens': True,     # adds [CLS] and [SEP] tags\n",
    "    'return_attention_mask': True,  # useful for distinguishing between actual data and padding\n",
    "    'pad_to_max_length': True,      # to ensure all sequences have the same length\n",
    "    'truncation': True,\n",
    "    'max_length': 256,              # set the maximum length for sequences\n",
    "    'return_tensors': 'pt'          # use 'pt' when using PyTorch, 'tf' for TensorFlow\n",
    "}\n",
    "\n",
    "# Load data\n",
    "print(\"Loading raw data...\")\n",
    "data = pd.read_csv('consumer_complaints.csv')\n",
    "data = data[['product', 'consumer_complaint_narrative']]\n",
    "data = data.dropna()\n",
    "categories_to_drop = ['Consumer Loan', 'Student loan', 'Prepaid card', 'Payday loan', 'Money transfers', 'Other financial service']\n",
    "data = data[~data['product'].isin(categories_to_drop)]\n",
    "\n",
    "# Sub-sample to speed up the training process \n",
    "if SUBSAMPLE: \n",
    "    data = data.sample(frac=0.25, random_state=SEED)\n",
    "\n",
    "# Example label dictionary for demonstration\n",
    "label_dict = {label: idx for idx, label in enumerate(data['product'].unique())}\n",
    "\n",
    "# Prepare data\n",
    "data['label'] = data['product'].replace(label_dict)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data.index.values,\n",
    "    data['label'].values,\n",
    "    test_size = 0.2,\n",
    "    random_state=SEED,\n",
    "    stratify = data['label'])\n",
    "\n",
    "# Define data type in the original dataset\n",
    "data['data_type'] = ['not_set'] * data.shape[0]\n",
    "data.loc[X_train, 'data_type'] = 'train'\n",
    "data.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Define augmenters\n",
    "aug_syn = naw.SynonymAug(aug_src='wordnet')\n",
    "aug_swap = naw.RandomWordAug(action=\"swap\")\n",
    "aug_delete = naw.RandomWordAug(action=\"delete\")\n",
    "augmenters = [aug_syn, aug_swap, aug_delete]\n",
    "\n",
    "# Function to apply data augmentation to text\n",
    "def augment_text(text, augmenters, num_augmentations=1):\n",
    "    augmented_texts = [text]\n",
    "    for _ in range(num_augmentations):\n",
    "        augmenter = random.choice(augmenters)\n",
    "        augmented_text = augmenter.augment(text)\n",
    "        augmented_texts.append(augmented_text)\n",
    "    return augmented_texts\n",
    "\n",
    "# Check class distribution (we will use data augmentation to oversample underrepresented classes)\n",
    "class_counts = data[data.data_type=='train']['product'].value_counts()\n",
    "\n",
    "# Determine maximum class count \n",
    "max_count = class_counts.max()\n",
    "\n",
    "# Augment minority classes to balance the dataset\n",
    "augmented_data = []\n",
    "for product, count in class_counts.items():\n",
    "    if count < max_count:\n",
    "        subset = data[(data['product'] == product) & (data['data_type'] == 'train')]\n",
    "        needed_samples = max_count - count\n",
    "        while needed_samples > 0:\n",
    "            for index, row in subset.iterrows():\n",
    "                if needed_samples <= 0:\n",
    "                    break\n",
    "                text = row['consumer_complaint_narrative']\n",
    "                augmented_texts = augment_text(text, augmenters, num_augmentations=1)\n",
    "                for augmented_text in augmented_texts:\n",
    "                    augmented_data.append((augmented_text, row['label']))\n",
    "                    needed_samples -= 1\n",
    "\n",
    "# Create new dataframe with augmented data and combine it with the training dataset\n",
    "augmented_df = pd.DataFrame(augmented_data, columns=['consumer_complaint_narrative', 'label'])\n",
    "train_data = pd.concat([data[data.data_type=='train'][['consumer_complaint_narrative', 'label']], augmented_df], ignore_index=True)\n",
    "\n",
    "# Ensure all entries are strings \n",
    "train_data['consumer_complaint_narrative'] = train_data['consumer_complaint_narrative'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n",
    "\n",
    "# Continue with tokenization and creating DataLoader as before\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_data['consumer_complaint_narrative'].values.tolist(),\n",
    "    **tokenizer_params\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='val']['consumer_complaint_narrative'].values,\n",
    "    **tokenizer_params\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(train_data['label'].values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(data[data.data_type=='val']['label'].values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "\n",
    "# Load device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the model with dropout\n",
    "class DistilBertForSequenceClassificationWithDropout(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels, dropout_rate=0.3):\n",
    "        super(DistilBertForSequenceClassificationWithDropout, self).__init__()\n",
    "        self.distilbert = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.classifier = torch.nn.Linear(self.distilbert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        # Get the outputs from the DistilBERT model\n",
    "        outputs = self.distilbert.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = outputs[0]  # (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        # Apply dropout to the first token (CLS token) in the hidden state\n",
    "        pooled_output = hidden_state[:, 0]  # (batch_size, hidden_size)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        # Pass the pooled output through the classifier layer\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        # Calculate the loss if labels are provided\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
    "\n",
    "        return (loss, logits)\n",
    "\n",
    "model = DistilBertForSequenceClassificationWithDropout(model_name=\"distilbert-base-uncased\", num_labels=len(label_dict))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# AdamW for Adam optimization with Weight decay\n",
    "optimizer = AdamW(model.parameters(), lr=LR, eps=1e-8, weight_decay=0.01)  # Added weight_decay for L2 regularization\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=len(dataloader_train) * epochs)\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "# Initialize lists to store losses for plotting\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Ensure the directory for saving models exists\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "# Training loop\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, ncols=100)\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "    # Save the model at each epoch \n",
    "    torch.save(model.state_dict(), f'models/finetuned_BERT_epoch_aug_{epoch}.model')\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    training_losses.append(loss_train_avg)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score(predictions.argmax(axis=1), true_vals, average='weighted')\n",
    "    val_accuracy = accuracy_score(predictions.argmax(axis=1), true_vals)\n",
    "    validation_losses.append(val_loss)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    tqdm.write(f'Accuracy: {val_accuracy}')\n",
    "\n",
    "# Plotting the training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs + 1), training_losses, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
