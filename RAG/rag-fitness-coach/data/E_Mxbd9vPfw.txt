hey folks
dr michael jordan here for renaissance
periodization rp plus rp university
lecture three theory of science drawing
conclusions from the research
how do we go from looking at studies to
developing a consensus
understanding of what's really going on
in a specific topic
on the agenda today we're going to talk
about the limits of individual studies
and boy
are there a lot we're going to talk
about how to find the balance of the
evidence on a subject
talk about how to sort studies on their
validity to make the balance
even better how that's done in reviews
of various kinds
what research volume has to say about
this
and wrap it up with consilience
conclusions and the types of conclusions
we can draw
so let's get right into it
why can't we go see one
study and just say boom
that's what's going on creatine
causes faster sprinting one study
all sprinters take creatine from now on
well
conclusions could be based on error
the conclusions of a study may not
actually reflect the reality of what's
going on so
what types of air are there well
generally speaking i think they're about
four four things that can go wrong
to get a study to actually end up not
showing
what it's showing
now before we go into these four
different types
i guess there's a fifth zeroth type
that it could just be due to statistical
error
like even if you have a study that's
significant at the .05 uh
p value level what you
end up concluding from that is very
likely to be correct but just by pure
chance could be wrong
so we never go by one study
because it has like a five percent
chance of being wrong now like
if that's the only kind of error we
could expect
uh man you know that would be pretty
good i could do a lot of things with a
95
certainty especially like harmless
things like changing up your training
uh so that would be the end of the world
but we got to mention that first that
even if the study is perfect
uh just pure statistical chance can can
be something to blame and
and check this out you know if we take
two studies and they both show the same
thing they both have a 0.05
probability uh or p value then man you
know like um
you know 95 or 0.05 percent of their
chance that they're wrong 0.05 times
0.05
that's a really low chance at the wrong
but that does not count all the other
sources of error here they are number
one
is design error the study could just be
designed poorly and thus the conclusions
is trying to derive
are wrong right it can't actually drive
them accurately
for example you are trying to detect the
presence of a certain compound
that says that your cells are you know
experiencing hypertrophy
but it turns out when you die for that
compound right you inject a dye into the
muscles after they're taken out through
biopsy
and you want the dye to show up on your
you know electron microscope or whatever
or just your light microscope
and you see okay well there's tons of
dye here not there that means fast which
fibers go faster or something
what if you use the wrong dye for the
kind of compound that you're using
it happens all the time right it's
happened tons through scientific history
you die something nothing shows up you
go back there's no difference that means
fast which fibers don't grow faster than
slow twitch oops wrong
right so there could literally be a way
that you somebody could tell you if
they're you know really really good at
science in that field
we could look at what you're planning to
do and be like that's wrong but if
there's nobody in your laboratory that
catches that it could just be wrong the
entire time
and all of the conclusions of your study
are totally suspect
next even if you have great study design
the execution of that study
could be problematic and could
eventually be erroneous
we call that procedural error you design
the study super well
your graduate student is executing the
study and
uh he's injecting lab mice with a
pro-growth compound
some of the mice get the pro-growth
compound some get the placebo injection
of just fluid
um and because you know the injection
itself gets immune response you don't
want anything so you inject both animals
one with just you know
uh bacteriostatic water and the other
with bacteriostatic water plus this
growth enhancing compound we're trying
to see if it works
and uh you know it's a grad student uh
you know like he just like sort of broke
up with his girlfriend going through a
rough time
and it's just like listening to music
when he's injecting the rats and you're
not even in the fucking you're the head
researcher you're not even in the
fucking lab you're at a conference
you know studies run themselves with
good grad students who can get good and
even if he's not trying to fuck shit up
he could just like accidentally for two
weeks like inject the wrong animals with
the fucking growth compound the ones are
not supposed to be getting it
fuck and then what is he likely to do be
like hey
i pissed away fifty thousand dollar
grant because now the results are
bullshit
probably not so he's gonna be like fuck
fuck fuck fuck and he's just gonna go
back to go and do the right injections
or he might not even
fucking notice but even if he notices
you're probably not going to tell your
shit
so then you you get this published
result and you're like oh well looks
like the growth compound didn't really
work
um because both of them got it right
they both got about the same
person he turns out it's a fucking
miracle drug which you couldn't detect
it because of people fucked up
this is one of these things that if
you've never been in the research uh
profession which is totally cool you
don't fucking need to be in the research
profession to know how to do science
properly
it sure as hell illustrates this really
well for you um i used to get into quite
a few
facebook discussions about like well
this study says this so we should
believe it and i'm like
do you understand that a grad student
could have just made all this up
they're like really no way like have you
ever been around grad students in
research and undergrads do research
right they come and hung over and do the
shit
right you trust these people and it's
unusually they're trustworthy but
they're not trustworthy enough
that when you get a real especially real
abundant conclusion like whoa this study
says that like the shit's happening it
clearly doesn't seem like it should be
don't go running away to the presses and
being like that's it the world
is totally different than we thought
hold up hold up hold on who did this
the injection of animals they're like
well you know phil he feels a great guy
like
sure even great guys make mistakes and
sometimes they lie about it okay
so procedural air fucking happens so
just another chance for a study to be to
be wrong enough for us to be skeptical
of one study
next interpretation and reporting error
all right
so for example uh they can do
uh you know uh study on carcinogenic
effects
of various compounds and animals but not
specify age differences between animals
it turns out that when the animals are
all really old
like way way old like artificially kept
alive in labs
much longer than they would be normal
that some kind of compound makes them
have more cancer um
but they never really specified that and
you're like fuck this thing just causes
cancer but it turns out during the
normal lifetime of the animal this just
never fucking happened
so the reporting error was that they
never included this piece of information
by the way the only rats we saw this in
were the super fucking old rats in both
groups not
like all of the rest of them real shitty
of them to do that maybe by accident
maybe on purpose
but definitely like when you're reading
a study
you're not looking at the study results
you're not a clairvoyant
you're looking at what people said about
the study the people that did the study
and if they're biased you may be getting
a real jaundiced account
of what happened right but you know you
might be getting a good account again
there's where the air comes from you're
not really quite sure
lastly this doesn't happen often
but it happens often enough often enough
for us to not run to the presses with a
conclusion from one study or even two
because it could be this and that's
number four fraud
okay the note here says failure to
release raw data the milwaukee project
so the milwaukee project
is i believe still cited in a variety of
sociological textbooks sociology
textbooks
um and this cool wikipedia article about
it if you just type in milwaukee project
intelligence testing and it'll come up
and what they did was
uh the milwaukee project is they tried
to raise the iq of sort of low
socioeconomic
uh group children
by having them attend like special
schools and getting three
hot meals a day and getting super
advanced tutoring all the time
and what they showed with the milwaukee
project was that if you give like the
tender love and care and the super
precise
inputs from society to people who
basically started out
very low iq very low iq parents all the
shit like
living in bad situations and you just
poured resources into them
the milwaukee project showed the results
were published that they literally
managed to equate iqs back up to normal
and sometimes even above normal
holy fucking shit
imagine if that was really the case
i mean you know i'm as libertarian as
the next person
but i'd start to be in hell a favor of
like
really big social programs that just
fucking solve
poverty and solve the education crisis i
mean fuck
like it just basically says like if you
pour enough resources and real careful
about just giving and giving giving
people literally just make up crazy
deficits in intelligence
and we know how much intelligence
predicts as far as life success and if
you can really do that with children
i mean the fact that we're not trying
desperately to do that with nearly all
children is a fucking crime basically
so a lot of the milwaukee project that
data
people who really wanted to believe it
they just took the shit and they ran
with it they put it in textbooks
they're sociology students right now
learning that that's a thing
so when they're advocating for public
policy no wonder they're advocating for
huge social intervention
that's just fucking logical at that
point here's the fucking problem
the milwaukee project came at the end of
an era in research about iq
in which most of the experts in
intelligence realized that
uh iq measured intelligence was uh
largely what's called intractable right
um
if you have uh individuals especially as
they reach their teen years and
adulthood
but even as younger children there's
just not much you can do to take a low
iq group and boost it into the average
range
right like good nutritions critical
but like as soon as people are eating
enough calories just to have a normal
body weight and they're not crazy
vitamin and mineral deficient
and if they like just go to school um
all the rest is like really small
differences like if you just give them
all the other studies if you just give
them the best conditions
you boost their iq by like a fifth of
what we would want
to bring it like to to normal baseline
right so it's like
if you pour an infinite amount of social
resources into people
all of our understanding until the
milwaukee project was like you're gonna
get
something but like for how much money
you're spending you could like fucking
end all disease or some shit before you
raise the iq all the way up to normal
it's
probably even possible with infinite
resources to raise their iqs up tomorrow
because there's some
something about it just with this
genetics or some kind of deep you know
in the womb influences or something
about the external environment
something's just not
moving and just pouring resources into
people doesn't just make them linearly
smarter
like the milwaukee project suggested so
when it was published
people in the sociological field some of
them not all of them
people in in media right this was before
social media
um and so a couple decades ago and they
were you know there's tons of
people covering it was so amazing what a
discovery this is great i mean it's
great news right and
the people who actually did intelligence
testing and educational psychology
pretty much all of them were like huh
boy that
that that sounds neat can we get the raw
data
what does that mean that means you talk
to the researchers and this is super
super common in science
and you want to try to reanalyze their
data with other statistical methods to
see if you can catch any bugs or
anything like that
and you just ask for the raw data like
you know i think clearly they
administered the study
and they took you know uh various
developmental markers they did various
iq tests at various times they
sort of specified how you know when
they're delivering hot meals how many
calories we're doing
how much time they spent with a
psychologist working on various problems
and tutoring like all that stuff is data
that they collected
hold on and you want to see that if
nothing else just to replicate it again
some other place
and do like a chicago project or you
know like you know florida project and
just do this in another because this was
done in the milwaukee
sort of urban and suburban area you know
you could just do it in a bunch of
places and it fucking works works works
fuck we just solved like half of
sociology all at once
when they requested that the researchers
release raw data the request was denied
it was just never answered so they're
like
so can't have the data and they're like
nobody got back to them and they're like
fuck's going on people started looking
into it and it turned out
with the head scientist behind the
milwaukee project was
shortly thereafter convicted for
large-scale research fund fraud
she's basically buying personal items
with research money
okay real bad news
turns out the preponderance of the
evidence
about because they did a couple of
investigations the milwaukee project
study as described literally never
happened
like the researcher just made it up
he just wrote out the the study just
wrote out the manuscript and submitted
it
it means literally they never went to
any of these places never fed any
children
everything was fake does that happen
often
fuck no it's super rare because you get
a deep shit doing that and most people
like if you're in science like
you know you're not getting the big
bucks right doing making up studies
for to still have your fucking shitty
job in academia is not exactly like
most people just don't do that but it
happens
especially when you see crazy aberrant
results fraud
happens so if so the milwaukee project
unfortunately still described in many
sociology textbooks
but it's just total bullshit it's
literally total bullshit and they've
done
dozens of studies of a similar type
after that and it turns out
raising people's iq's way harder than
people would
think from the milwaukee project so
anytime you see a study that's like way
too good to be true
oh it might be right it probably isn't
but we can't be sure here's what we can
be sure
about individual studies are not
powerful enough to give conclusions
can you fucking imagine if the one
milwaukee project study
was used to change all of united states
social policy
and take all the spending we spent at a
bunch of shit cut that shit in half
and then put the rest of the half gdp
fucking like two trillion dollars
every fucking year to like this to like
just
raising people's iqs in ways that turned
out to be completely wrong you would
literally you would be better off
burning the fucking money
right so really really bad idea which is
why we don't
conclude on individual studies ever
ever very justin bieber bieber at all
2003
never say never which already is a
contradiction in terms if you were
paying attention
but boy had a point right pretty close
to
never are we going to do individual
studies and conclude
huge swaths of actionable stuff from
them
really bad idea so what do we really
need to conclude stuff well
we need the balance of the evidence how
do we do that four-step process pretty
simple
first you take all of the studies on a
subject
remember in the milwaukee stuff with the
intelligence there's like 15 studies
that say
jack shit happens or very little happens
and then one study that says a lot
happens well if you take them all you're
like
well it just doesn't fit how come all
the other ones don't find that right
number two you find out what the average
or net balance or most common conclusion
is
and there's a good word to be said for
all of that right so if you find out
what the average conclusion is something
like the milwaukee project can still
boost the average
but now it boosts it from like you can
raise iq you wanted to raise iq by 15
points but you
you know all the studies say two the
milwaukee project says 17
so you average is instead of two it's
three that still says it's kind of
shitty
right but you know two is worse than
three so maybe even that's
loosery so you can go with most common
like if 10 of the studies say
boosts iq by two points five of the
studies says it boosts it by one point
or three points or something and one
study says 17
you're like yeah we're not going to
worry about that 17 because seemingly
almost always we find that it's two so
it's probably two okay
and we'll get into how to do statistics
on that but generally speaking
you just kind of try to in some way good
faith effort
to get a feel of what does the balance
of the evidence
really say and it can be in frequency it
can be an average
that's not as important as just trying
to get a feel you can probably do both
and see which one seems like it's more
legit
and then number three is the result you
get from that assessment is your most
likely
tentative way to the truth right it's
not for sure the truth but look if we do
10 or 15 or 20 studies on something they
pretty much
all say damn near the same thing man
that's really likely that the truth is
pretty close to that it could be off
but sure as hell more likely than with
one study right
all the studies have to be taken cause
all the studies have a little bit of
error
but enough of that usually cancels
itself out and
probably brings us closer to the truth
you have to avoid studies
in isolation i'm fucking notorious for
this
but people ask me hey what do you think
about this one study
my usual answer is i don't think much
about it at all
but i think in the context of all of the
other studies on the subject
this adds to the body of literature in
the following way all the other studies
say this this study could either say
the opposite or it can say more of this
and i say look if it says the opposite
i'll say you know it's interesting study
says something very different i would
like to see more studies try to
replicate it
but if it says the same thing it'll be
like an interesting study and maybe it's
you know just
statistical chance but sure does make
sense with everything else always have
to go back to the body of the evidence
right how to avoid citizen solution it
happens
all the time on social media people link
one study at a time
they're like hey this new study says
milk causes cancer like wow fuck that's
it
that's it stop drinking milk cause it
causes cancer they're like really like
no not fucking really
how many other studies on that have we
done like like 100 right and 99 of them
say milk doesn't cause cancer
50 of those say that milk probably
prevents a bunch of different kinds of
cancers
so we think one study good enough
clearly that's not the case
right now next point we can do a better
job than this
we don't just take all the studies and
just fraction them out of what does this
one say what does that one say count up
tally up and give the average
we can do a little bit better we can
sort all of these studies
in one topic on validity
let's say we stick with the milk and
cancer one does milk cause cancer
we got a hundred studies we can look all
of the studies on milk and cancer
look at all of them at the same time we
can rank them
on their internal and external validity
okay so we have a list
internal and external and a 100 list
you know with the best internal validity
studies ranked one through 100
best to worst and then external learning
100 best worst
and then we test another hypothesis
within this
realm of studies we ask what do the more
valid studies tend to say
versus the least valid studies and
is it an agreement because it could be
that if we look at the
bottom 50 studies of validity the 50
least valid studies
25 of them say milk causes cancer 25 of
them say it doesn't
we look at the top 50 and that's the
same thing 25 plus 25 minus
so we're like i don't know you know both
valid and invalid studies or less
and more valid studies kind of say the
same thing so it's kind of a fucking
wash but here's the deal
if there is an agreement we got
something so let's say you take the 50
least valid studies
25 of them say milk causes cancer 25 of
them say it doesn't
you take the 50 most valence studies
48 of them say no cancer causation or
correlation
two of them say yes it does
oof interesting very interesting why is
it interesting
because more valid studies are more
powerful they lend themselves better not
in isolation
but in aggregate to better conclusions
if your best evidence
if the the better the evidence is the
more it shows that milk is safe for
cancer
and the worse the evidence is the more
it's likely to show that it's not
fuck man that's a pretty good argument
for
milk probably doesn't do shit with
cancer now
probably not definitely but it's
definitely a really cool piece of the
puzzle
i made a note to myself here and you see
it on your screen to use the common home
environment effect as an example i
have a curiosity about sociology and
psychology god knows what reason no
friends that's what it is
um so this is a really cool thing what
i'm about to say is really really really
counter-intuitive
bear with me if you don't agree with me
uh you can read all the pertinent
uh psychological research and bore
yourself to tears
the common home environment is the
environment that two children
experience in their home growing up for
their entire lives until they leave the
house
like uh do your parents tend to fight a
lot in the home do they tend to
uh tell you no you gotta do your
homework or are they like hey you know
just make sure you get your homework
done or do they say nothing at all um do
they watch a lot of tv or do they not
stuff like that
right that affects both children
relatively evenly okay
so that's the common home environment
and there's an idea about
how much of that affects the eventual
personality of children right so like
how outgoing are children how neurotic
are children
as adults right based on how they were
raised in their home
like are children who are get yelled at
more by their parents
are they more neurotic when they grow up
or are they less neurotic or something
like that that's like a fine
hypothesis there right so the question
there is how much does the common home
environment
have an effect on children's eventual
personalities
as adults that's our research question
well uh there's a bunch of research on
this
and the aggregate surprisingly
showed that it's less than ten percent
or it's about ten percent
of an effect uh on total personality it
explains ten percent of the variance
what does that mean
that means that the number one reason
you have the personality that you do
is something like your genetics
and or environmental factors that are
not the common home environment for
example
like your nervous system wired itself in
the womb
it's based on fucking sheer random
chance or on some kind
of you know environment you had in the
womb because of your mother eating or
drinking something or just her genetics
or something like that
or just a random chance like you know
why are you confident
when when you're older because you uh
were crossing the street one time
and uh you almost got hit by a car but a
firefighter who just happened to be
crossing the street he pulled you aside
and and you know he's like oh careful
and and you
you're like you were like eight you're
like oh my god thank you and you look up
at him he's like
don't worry son you know you're good to
go be confident
that's the key in life and you're like
the firefighter speaks to you when
you're eight
fucking god could say shit you could be
like that's nice what does a firefighter
think
he said that you're like confident
confident confident you thought about
that like the rest of your life
and you just fucking affected your
personality to the point where you just
prioritized confidence you grew that
internalist
as something that you really valued and
you eventually were more confident right
maybe something like that but that's not
common home environment you know fucking
parents don't bring a fucking
firefighter to their home
and be like teach these fucking kids
about confidence right and if they did
that you'd be like ah fuck my parents
are trying to teach me shit i'm not
gonna learn
right so the common home environment is
the stuff after that it's like what
actually happens in the home
genetics is super important individual
just chance variations or other things
we can't explain
um and it's called a unique environment
and then
there's a common home environment you
know what's the standard story in uh
sort of like colloquial psychology that
you know
like uh common home environments
probably number one like you know in
fact tell you what man these kids aren't
raised right today you know shit like
that like your parents didn't fucking
beat you that's why you're
acting out uh you know like they didn't
teach you proper morals
so you know that's why you're neurotic
because your parents did this or that
too much tv not enough too much yelling
not enough and
it turns out that the common home
environment versus what most people
think is like well at least 50 percent
looked like it was 10. but let me get to
the point allow me to get to the point
uh a couple of researchers sorted all
the studies on common home environment
effect on personality
on their validity and uh especially like
internal validity like how many
confounders they take into effect
and they noticed that the more
internally valid the studies were
the lower the effect of the common home
environment close to zero
holy fuck now does that mean something
for sure no
but if you were of the opinion that the
common home environment is like super
powerful
as an effect on personality it
definitely affects other things
uh you're probably wrong because when
the studies get better
the effect shrinks more and more and
more if the studies are not so great
the effect is bigger probably because
the count founders get in there and it
looks like common home but really it's
not
really interesting way to do things and
it shows us that not only do we need to
take
all the studies in aggregate but we need
to look at all the studies and see how
good are the studies
rank them and say what do the better
studies say what do the worst studies
say
if there's no relationship whatever it's
just a dead end fine but if the better
studies say
like ah looks like this one thing is
true that one thing is probably more
likely to be true
really really good tool to use now
here's the really great news
you don't have to do the shit yourself
isn't that awesome researchers do that
in the form of reviews and they publish
these reviews they take a bunch of
different studies and they do those two
things
they aggregate them all and tally up the
effects and a lot of times they'll
analyze the validity and say well what
are the more valid studies show
that's fucking sweet right there's a
couple of ways of going at this two
really good ways in one way that's not
so great but has its uses
the first is what's called a
comprehensive review it's a collection
of all of the good studies on a subject
and a discussion of a grand conclusion
that
emanates from them that discussion can
even be a discussion on validity so
there can be validity sorting
notice i said all the good studies
comprehensive reviews at least the good
ones
usually have like a minimum validity
threshold right so the studies that just
are really shitty validity they don't
even fucking include them shit so
they're just like whatever fucking that
study sucks
right so they get like the you get like
100 studies they'll take like the top 80
or the top 50
and the really shitty ones they're just
they're not even bother looking at
because they know it's already garbage
it's just gonna be more noise right
and then you'll have to really read the
study to see like oh well the validity
analysis was like that
right so they just get rid of them and
then you have to do less validity
analysis internally because you know all
the studies are pretty fucking rock
solid right
so comprehensive review takes the good
studies still ranks them on validity a
lot of times
talks about what the likely grand
conclusion is if you're more numerical
and you should try to be at least when
it's conducive you can take a type of
comprehensive review what's called a
meta-analysis
a meta-analysis does exactly what a
comprehensive review does but it doesn't
mathematically so it applies a
mathematical procedure
that basically analyzes effect sizes and
what it can do is tell you like how big
of an effect is this having
on average like you want to see okay um
how big of an effect
am i going to get from creatine and
muscle growth well they can do a
comprehensive review and say it's going
to be a good effect
but they can do a meta-analysis and say
actually here's exactly the average
effect you're looking at
right because like we 10 studies and
they all have effect sizes and we sort
of treat average them and
that not only do they average them but
they see you know how many
subjects are in each group so that the
validity is reflected and how much
importance we put into the effect size
so it's a validity treated effect size
analysis really powerful
it's very limited and precise
conclusions but really robust
conclusions
so ideally you want to see comprehensive
reviews and if meta-analysis exists
they're fucking sweet they have their
own problems and limitations but they're
a pretty fucking good start
what you should look out for are
narrative reviews
i sort of can't really believe that
people do this in science still but here
we go
a narrative review does not have to be
comprehensive
a narrative review is kind of like a
story someone weaves about how they
think shit works
they can include some studies from a
field but not all of them
and they can weave multiple fields
together and it's not a really good
piece
for extrapolating conclusions
if a narrative review says this xyz man
they just might have missed a bunch of
studies they had like something they
wanted to say
but it's a great tool for exploring
deeper thoughts on the subject and
possibly generating
some really good hypotheses you could
have a narrative review
on muscle damage and hypertrophy that
says now look muscle damage probably
just doesn't have much to do with
hypertrophy because of the following
a bunch of studies then look at all the
studies but they kind of weaved a story
of like if this study is true then
then look at it with this method plus
that ooh this looks really bad for
damage
that doesn't mean that that is good
evidence for the fact that damage and
hypertrophy are you know unrelated or
antagonistic to each other
but what it could say is like man we
really should have some other good
studies or a comprehensive review or
meta-analysis
that looks at the subject in real good
clarity and depth to try to figure stuff
out so narrative review
is kind of like the hypothesis
generating part of a review
if you can avoid narrow reviews for the
most part that's a really good idea
comprehensive reviews and meta-analyses
are king
all right moving on okay so we got some
studies
how many so we know that one study is
not good enough to include dick
we know two studies is better we know
three is better than two how many
studies
do we have to have on average to start
to be
whatever degree confident we are with
our conclusions right
now mind you the numbers i'm going to
give you here mostly centered on
exercise and sports science and
other sciences have different numbers
and they're really just real
just like a thinking experience like a
um just a real
broad it is sort of more example of how
you can think about it these numbers are
not set in stone they're not hard
cut-offs but they're designed to
illustrate a concept
of how sure you can be about conclusions
based on how many studies you have
here we go especially in sport and
exercise science but in a bunch of other
things too
one to four studies on something it's
basically good enough to say it's a cool
idea for further research
right it's a hypothesis generating act
at that point
just gives you really good guesses about
what could be happening
there are some exceptions like a design
demonstration like
if you say you have a stealth bomber
that is invisible to the naked eye
and you actually turn on the stealth
thing and it disappears one study is
good enough because it's fucking not
there
okay you fly it around you turn it on
and off fucking good enough you know the
military will give you a contract right
there on the spot
okay uh or you know deep experimental
physics like you run
it takes you a year to run one fucking
positron collider machine
you know they got the shit so internally
valid that one study might actually be
pretty fucking powerful
but in most cases if someone asks you
hey what do you think about
one to four studies about the subject
you say you know that's a you know
curiously this effect is going on
or it's an interesting new idea like a
lot of the as of this filming a lot of
the stuff on gut health
gut microbiomes isn't a one to four
study range based on like
exercise and gut health is literally in
the one to four study range and it's
like you know that's an interesting new
idea like that's what i think about it
they're like what do you think i should
do about it like you shouldn't do shit
about it
good as good as random chance because we
just don't know enough
now up to the next volume of studies
let's say there's five to ten studies on
something
this is the beginning of a likely
conclusion not a strong conclusion
but you can say something like well it
seems like
let's say someone says you know what is
the relationship
between range of motion and hypertrophy
and currently i believe it's about five
to ten studies towards the
ten side i think about range of motion
and hypertrophy
so you could say well it seems like
higher ranges of motion confer larger
degrees of hypertrophy
right but you're not going to go much
further than that so potentially if
someone's like well
would further research could it obviate
that and show that we had that all wrong
he'd be like yeah
that's totally possible yeah it's not
even unlikely but it just seems like uh
you know
higher range of motion cause more
hypertrophy right uh just just on the
basis of those studies
five to ten studies all right next up 11
to 25 remember these are like you know
not exact numbers necessarily so 11 to
25 studies
this is a pretty good footing in most
cases right you can say it seems
likely that not it seems like but it
seems likely that this relationship
exists
right you know if you have you know some
kind of analysis
of one supplement and it grows muscle
and it's most of the studies and it's
like 20 studies of it you see it seems
likely that you know this supplement z
grows muscle and someone's like really
sure like not sure but it seems pretty
likely it's like fucking 20 studies are
getting up there
another way of saying it is the the
chance of statistical and all the other
error noise
uh to chance of it biasing all the
studies it really starts to fall in the
11 or 25 range
25 plus studies on something especially
very good studies
it starts to become very strong evidence
right then you can say it is
highly likely that this effect happens
just a really interesting example
because people who are not
scientifically literate continue to
debate this all the time
sweeteners and health right especially
acute health like what's bad about
drinking a diet coke and doing that like
one diet coke for
you know for three months straight is
that gonna affect my health poorly
um there are hundreds of studies on that
hundreds
and almost all of them are tilted to one
side if nothing's gonna happen so when
people say like well you think
artificial sweeteners are
are okay for your health like how sure
are you about that pretty fucking sure
really fucking sure these are the same
people that'd be like man
fasting is great for autophagy and
you're like how many studies are on that
they're like there's one study on yeast
you're like sweet that's a wild guess
right but to them you know 100 studies
is not good enough when their biases
don't point in that direction so
research volumes and meaning super super
important to keep in mind this is
super actionable stuff guys like you
look at
you know someone says hey what do you
think about this or you start to ask
yourself hey
i wonder what the relationship is of you
know uh
how much weight i lift like you know
three rm or one rm or five or m how
strong i get you look at all the studies
count the studies if there's like five
to ten studies on it you can probably
put it into your training plan and be
you know like sort of
hopeful that it'll work if there's 11 to
25 you can be pretty fucking confident
that it's going to work if it's 25 plus
studies it had better be in your fucking
training program already
and if it's one to four studies man you
know you can try it but i wouldn't try
it before me or some shit like that
because it'd just be totally wrong
perfect way to apply something like that
all right
second to last discussion on conciliance
and conclusions this is a
love this term i learned a long time ago
in high school conciliance is the
convergence of
multiple lines of evidence to the same
underlying underlying conclusion
right conciliance
multiple lines of evidence conclude
pretty much the same thing
the easiest example i'll give you just
as an analogy so you understand in your
soul what it means
um think back this could be you right
think back to a person you're in college
or high school
who's just a fucking asshole right and
someone maybe you're new to school
uh or you haven't talked to them much
and
you like had an interaction with them or
they were a dick to you
either people have bad days maybe you
were at fault
uh so on and so forth right so
how do you know if they're an asshole
well we can look for conciliants
you talk to some other people and
they're like oh uh jared feather
he's a total asshole i hate that guy
you uh look at how teachers treat them
and they're like
told the teachers are like had it with
this kid right
you interact with them numerous times
and pretty much
always bad and you know that that person
gets in trouble with the police
right and you see how they interact with
their own family their dicks to their
own family like mom drops them off at
school and he's like fuck you and he
closes the door and runs into school
you're like
alright it's not just you it's a bunch
of other people
it's a bunch of people of different
social strata teachers versus students
it's technical legal trouble and it's
all of that
family included man you know that mike
israel guy
probably a fucking asshole and someone's
like well are you sure like i'm not sure
but there's a consilience of evidence
pointing into the same thing
whereas here's we don't have conciliants
a person was a dick to you but you
talked to some other people that you're
close with at school
and they're like she's been fucking
super to me and like you know he helps
sick children in a spare time and you're
like fuck me
maybe i was a dick maybe it's just a bad
time you would talk to the person
they're like dude sorry like i was super
stressed out that day i totally didn't
mean what i said
let me make it up to you're like don't
even bother like totally cool right
there's just no conciliant so sometimes
you know a lot of times
you get one group of people or some
people say that person's a piece of shit
some person say that person's cool as
fuck
so what's the net balance conclusion
well there is no net balance it could
either be
complicated or just don't know enough
right but when you have consilience
that's a pretty fucking good sign that
some shit is going on it's not a
guarantee but it's a pretty fucking good
sign
so what do we have to do to get
conciliants in formal research right not
just high school bullshit well let's
look at it number one
dozens or more of good studies pointing
into one direction
right number two mechanistic studies
examining how like the actual thing
happens how the hypertrophy happens how
the molecules affect each other and
artificial sweeteners for example
we have short term research weeks of
effect we have long term research
years of effect all of those time scales
have been examined so they're not just
good studies pointing into one direction
but the studies are examining multiple
time scales and multiple ways of
analysis
you look at it and practical experience
has good reviews on it
artificial sweeteners one you're like
hey diet coke
drinker and they're like what up they're
like how are you feeling they're like
great like how long have you been
drinking diet coke for like
40 years like okay are you gonna die
soon they're like i don't know i don't
fucking feel like it you talk to tons
and tons of people
and you're like waiting for people to be
like yeah man artificial sweeteners
killed my dog bro
like i used to give him diet coke and he
just fucking died and you just never
hear that shit and everyone's like a
fucking great great great great great
works
here's another good one squats right
like mechanistically we know how muscles
contract and attention is applied squats
past that test
short-term squats increase your shit
long-term people who squat for a long
time have big fucking strong legs
more than dozens of good studies in one
direction good reviews and practical
experiences go fucking talked about is
when power says hey squat's going to
make me
fucking big lugs and like fuck yeah how
many people are going to say no
the worst you'll get usually is people
that are like you know squats aren't the
only way to skin the cat right but
you'll be like but if it works for my
body type and i don't get hurt by it
they're like yeah fuck it's
going to work right looking pretty good
and
number four not the most important the
least important of these but
prominent practitioners coaches and
doctors
so on and so forth support it right like
the all the evidence-based people are
like yep that's the shit
right this is not the only piece of
evidence you need but it's a good icing
on the cake
when you say okay squats are going to
get big legs you look at all the coaches
the best bodybuilders powerful center in
the world they're like squat squat squat
squat squats
all right and you look at like you know
really good like medical doctors like
squats are safe
right and the practitioners themselves
the athletes themselves like i fucking
swear by squats it's awesome like branch
worn shit like that
you got something good man you'll
probably have an effect that's real
right then you can say it works
right so when someone says do squats
make your legs jacked yeah
they work now next time you see a
fucking social media post
that says this works about some kind of
detox to you some rap does it
really have all four of the consilience
check marks
even some of them let's look at detox
tea for example
dozens are more good studies pointing to
detox tea working nope
mechanistic zero short term zero studies
on that
maybe like one shitty one long term none
good reviews zero reviews from practical
extra good reviews from practical
experience
yeah people that fucking instagram the
account and the fit t
owns them totally and then there's
fucking thousands of other people like
hey you try fit t they're like yeah what
was it like like
it cost money did it work like no i
fucking pissed
right that so you know the reviews
aren't that great prominent
practitioners recommend fit tea not the
serious ones
good coaches fuck no scammy instagram
coaches sure
do doctors support it that are fucking
actually trained medical professionals
on the net balance
no way does it work fucking no probably
not
right all right
lastly we've been talking this entire
time or most of this time
about you know conclusions pointed in
one direction
we're sort of assuming that that all the
questions are like yes or no questions
or like either it has an effect or
doesn't or it's this effect or it's that
things get a little bit more complex
than that let's talk about the different
types of conclusions you can draw
after enough of the data has been looked
at so this is pretty much after you
develop
even a conciliance you can have a
different
degree of conclusion so they're ranked
four three two one
rank backwards on purpose because number
one is the best kind right
but we can still have a workable
understanding to some extent
even with the fourth one so number four
data unclear
this can even occur with a lot of
studies for example gut microbiome and
general health
plenty of studies now not a zillion but
plenty
but the relationship is really
complicated
our current tools of analysis don't have
enough precision
or where we're doing studies is just not
showing us what we really need
to have conclusive evidence for example
and dr gabrielle fondara one of our rp
coaches is a gut health expert and she
says this all the time
people say like okay so like do i have
like a more good bacteria in my gut like
how do i get
more good bacteria there's no such thing
as good bacteria or bad bacteria there
are bacteria there's certain effects and
certain other effects and some of them
can be described as more often bad than
good
but if you have like very few of them
then that's bad and there's like
literally like hundreds of different
types of bacteria in your gut
man there's not just two types right so
when people say like well
how does the gut microbiome affect
general health like fuck man
there's a hundred different types of
it's like saying like how does exercise
affect your body
like uh you know there's a whole def a
lot of different kinds of exercises
like okay like will running make me jack
no but i thought you said exercise makes
me jacked well some kinds do
right and gut microbiome and general
health is like at least as complex as
that
so sometimes it's just you have to say
like like what do you think about the
gut microbiome and general health like
well the data's a pretty unclear and
hopefully later
with more data and more in-depth
analysis we can move it down to one of
the other tiers but for now data unclear
is totally fine
we're not trying to lie to ourselves or
pretend we know shit data and clear
means data and clear
next one number three a little bit
better is a consensus
with caveats right uh so their caveats
are
basically big exceptions to the
principles or areas of mystery
right so for example um
we can say that um
you know anorexia nervosa okay
we can say that anorexia nervosa uh
definitely has cultural inputs okay
um so we can say that you know someone
says
hey you know do skinny girls in fashion
magazines and on tv
make people more anorexic because they
lead by example
this is one of those things where
there's a consensus with caveats
the answer is yes but
it is not only that input and the
relationship is fairly complex
if you are at risk predetermined risky
factors for anorexia nervosa
in some situations the landscape of
fashion industry and looking at the
magazines and look at the skinny girls
can push you into a more likely state
if you are not at risk it doesn't
fucking matter
and even if you are at risk some of the
times there is no push for a variety of
other complicated factors
so if someone asks you like hey does the
fashion industry promote anorexia by
accident basically
you'd say uh it definitely has a net
effect that's probably not
positive but the way in which it's
negative is fairly complicated
so that we can't say look the reason we
have anorexia in our society is because
of fashion magazine
definitely wrong huge caveat there
and then if we want to know more about
the situation we need more specificity
about exactly we're talking about
exactly how the
uh the disorder is acquired so on and so
forth so there's definitely
it's not just well it's unclear how
fashion magazines affect anorexia like
no that probably not a great
effect on average but there's tons of
caveats and situations
in which we can say look you know it's
definitely not all cultural inputs right
you don't just cause anorexia by
changing your culture it's
basically ubiquitous disorder and uh for
what it's worth
is hugely genetically correlated right
and in a lot of it is
due to internal brain conditions or
internal uh manifestations of psychology
this just have really precious little to
do with where the fuck is going on
outside
uh one of the ways of testing this is
the anorexics uh usually think they're
overweight which is insane because
they're almost all underweight
so when you say like okay you're just
you know you know you're underweight
but like mission accomplished right
because you finally look like a model
and they're like no no i'm i'm still
overweight like okay something's up it's
not just like monkey see monkey do it's
straight up not that simple so there's
an understanding there
but it's huge caveats to make sure we
don't oversimplify things
next as we learn more we can eventually
develop a strong consensus
okay an example there is high volume
training in hypertrophy
high volume you know under maximum
recoverable volume we know that
generally speaking from zero sets
to roughly 20 plus sets the average
individual grows more muscle the more
sets they do
it's not a fucking mystery anymore the
number of studies that confirms that is
into the dozens and dozens and dozens
it's just it's just a thing so that's a
very very strong consensus
there's one more way to go which is even
better and that's overwhelming consensus
that's when you have hundreds of studies
on mechanism on short term on the long
term
that's the true expression of full
consilience the category where
overwhelming consists
exists is aspartame and health right is
aspartame artificial sweetener bad for
your health the overwhelming consensus
is
fucking no now can there still be
caveats to that
can it disrupt gut microbiota to some
extent
that needs the gut microbiome to
readjust totally is the long term
in the long term can it make people more
prone to obesity we're not sure
but if you do a very good hypothesis of
is aspartame bad for health
in the in the term of months and years
almost certainly not
an ungodly amount of research here's the
thing
if you don't agree with that i don't
know how you live your day-to-day life
because there's a lot of shit you assume
when you go out and do this and do that
and pick up some food and put it in your
mouth
you're assuming shit that has less 80
behind it than aspartame
being bad for your health so basically
when we look at the world and we try to
understand it
we can draw these four different types
of conclusions all the way from
data unclear we just don't know yet man
it's super complicated we're working on
it
all the way through like okay we're
starting to understand some stuff but
there's big areas here where the
principles just don't line up yet and we
can't be sure
how the effect works like the anorexia
and cultural inputs from fashion models
stuff like
yes there's an effect but it's a very
complicated effect and we can't just say
like
you know reducing the number of fashion
shows in america is going to lead to a
decline in anorexia it could be some
kind of
reverse causation at that point then
there's a strong consensus we're pretty
fucking well understand what's going on
some caveats there like maybe some
people's mrv is lower and so forth so
forth maybe we don't know a ton about
the mechanisms but we've seen a very
very robust effect
and then there's overwhelming consensus
where it's like people who continue to
debate to point
to a huge effect and nothing novel like
nothing like what about gut microbiomes
just literally like well i don't know i
still think it causes cancer like oh my
god they beat that shit to death
and it just fucking doesn't right is
there a chance that even when we say
over all the consensus
that we're still wrong yes there is no
certainty in science
also in life but you know if you're
sure enough to wake up in the morning
and assume that the rising sun means you
probably have to go to work in two hours
you probably use the same level of
certainty to think okay
aspartame is probably not going to get
any cancer
that's it right so what's the purpose of
science fundamentally
to drive as much human understanding
into category number one
that's it and if it's in category four
we need more data we need
more good analyses on it we need people
to be logical so that they don't assume
that something
is at number one when it's really number
four and vice versa yahoo
more on that in the next lecture of
applying science that'll be lecture
number four
see you then
you